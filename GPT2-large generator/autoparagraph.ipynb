{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer #importing the main model and tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")#using the large parameter from GPT to generate larger texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 3.02G/3.02G [00:54<00:00, 59.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model=GPT2LMHeadModel.from_pretrained(\"gpt2-large\",pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1639,  481, 1464, 6758,  287, 5155]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'You will always succeed in Life' #input sentence\n",
    "\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')#using pt to return as pytorch tensors\n",
    "\n",
    "input_ids # checking the tesors returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will always succeed in Life, but you will never be successful in Death.\"\n",
      "\n",
      "\"I am not afraid of death, because I know that I am going to be with you when you die. I will be waiting for you, and I\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=50, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))#printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is the key to unlocking the mysteries of the universe, but it's also the source of a lot of our problems.\n",
      "\n",
      "In a new paper published in the journal Science Advances, a team of researchers from the University of California, Berkeley, and the National Institute of Standards and Technology (NIST) in Gaithersburg, Maryland, describes a way to create an artificial intelligence (AI) system that can learn from its mistakes and improve its performance over time. The system, which they call a \"neural network,\" is capable of learning to recognize patterns in images, recognize objects in a video, or even learn how to play a musical instrument. In the paper, the researchers describe how they created the neural network and how it can be used to train an AI system to perform a variety of tasks, such as recognizing objects and playing musical instruments.\n",
      "\n",
      "\n",
      "Neural networks, also known as deep neural networks or deep learning, are a type of machine learning algorithm that is based on the idea that a network of neurons is like a computer's processor. Each neuron is connected to a number of other neurons to form a larger network. When a neuron receives an input, it sends a signal to the next neuron, who in turn sends an output to another neuron. This process continues until all the neurons have received the input and have processed it. As a result, each neuron has its own unique set of inputs and outputs, making it possible for the network to learn and adapt to changes in its environment. Neural networks have been used for decades to solve a wide range of problems, including image recognition, speech recognition and natural language processing. However, they have also been criticized for their poor performance when it comes to learning from their own mistakes. For example, in 2013, researchers at Google's DeepMind AI research lab published a paper in Nature that showed that they were unable to improve the performance of their network when they made a series of mistakes while training it on images of human faces. They also found that the system was not able to distinguish between a human face and a dog face, even though the images were similar in terms of size and shape. These problems have led some researchers to argue that neural nets are not as effective as they are made out to be. But the new study suggests that this is not necessarily the case. \"We show that it is possible to build a neural net that learns from mistakes,\" said lead author and UC Berkeley professor of electrical engineering and computer\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Artificial intelligence is the key'\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "output = model.generate(input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, early_stopping=True) #setting length as 500 to generate larger output text\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.decode(output[0],skip_special_tokens = True)\n",
    "with open('AIBLOG.txt','w') as f:\n",
    "  f.write(text) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75273f6ed8af91899ebc591bf6ae2fd0716c5db2515d7097a000123632f4e53a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
